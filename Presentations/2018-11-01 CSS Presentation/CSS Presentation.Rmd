---
title: "Basic Statistics for Machine Learning"
short-title: "Stats for ML"
author: "Demetri Pananos"
short-author: "D.Pananos"
subtitle: 'You Could Call It "Statistical Learning"'
department: Department of Epidemiology \& Biostatistics \newline 
            Schulich School of Medicine \& Dentistry
institute: Western University
title-logo: ../western.png
logo-right: ../western.png
date: "`r Sys.Date()`"
fontsize: 12pt
output:
  beamer_presentation:
    keep_tex: true
    toc: false
    slide_level: 3
    template: ../WesternTemplate.tex
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      results = 'hide',
                      fig.width=4, 
                      fig.height=3, 
                      out.width="4in", 
                      out.height="3in",
                      fig.align = 'center',
                      size = 'tiny')

```


## Intro
### A First Approximation For The Difference Between ML and SL

* Some algorithms are built off of statistical concepts.

* Others seem ad hoc, with no immediate relationship to a statistical theory

* I would call the former *statistical learning algorithms* and the latter *machine learning algorithms*.

### A First Approximation For The Difference Between ML and SL

The name "machine learning" is an unfortunate name.  The machine "learns" the neccesary associations in both types of learning.

### A First Approximation For The Difference Between ML and SL

E.g.
* Generalized Linear Models are Statistical Learning
* Neural Nets are Machine Learning

### Goals

* Be able to understand what the chosen algorithm does
* Be able to explain it in laymen's/sophmoric terminology


### Will Require an Understanding of The Following

* Manipulation of Probabilities

* Expectations and Covariance

* The Very Basics of Likelihood Theory


## Probability
### Probability

Sum Rule

$$P(X) = \sum_Y P(X,Y)$$

Product/Chain Rule

$$P(X,Y) = P(Y|X)P(X)$$


### Probability
We can recover some very powerful rules just from these.  For example, Bayes' Rule

$$P(Y|X) = \dfrac{P(X|Y)P(Y)}{\displaystyle{\sum_Y} P(X|Y)P(Y) }$$


## Expectation and Covariance

* We're all familliar with expectations and variance for single variable distributions.
* Now, generalize to larger distributions.