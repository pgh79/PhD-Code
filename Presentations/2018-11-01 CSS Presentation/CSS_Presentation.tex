% Western Themed Beamer

\documentclass[12pt,ignorenonframetext,]{beamer}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{:}
\setbeamercolor{caption name}{fg=normal text.fg}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\usepackage{lmodern}
\ifxetex
\usepackage{fontspec,xltxtra,xunicode}
\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
\newcommand{\euro}{€}
\else
\ifluatex
\usepackage{fontspec}
\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
\newcommand{\euro}{€}
\else
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\fi
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
	\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

%%Color Themes
\usepackage{xcolor}
\definecolor{helmuth}{RGB}{79, 38, 131/250} % 
\definecolor{westernSilver}{RGB}{128,127,131} %

\usetheme{Madrid}
\useoutertheme{miniframes}\useinnertheme{circles}
\setbeamertemplate{navigation symbols}{}
%Set Beamer Colors
\setbeamercolor{palette primary}{bg=helmuth,fg=white}
\setbeamercolor{palette secondary}{bg=helmuth,fg=white}
\setbeamercolor{palette tertiary}{bg=helmuth,fg=white}
\setbeamercolor{palette quaternary}{bg=helmuth,fg=white}
\setbeamercolor{structure}{fg=helmuth} % itemize, enumerate, etc
\setbeamercolor{section in toc}{fg=helmuth} % TOC sections
\setbeamercolor*{titlelike}{fg=white,bg=helmuth}
\setbeamercolor{subsection in head/foot}{bg=westernSilver,fg=white}
\setbeamercolor{itemize item}{fg=black}
\setbeamercolor{enumerate item}{fg=black}

\setbeamertemplate{itemize items}[default]
\setbeamertemplate{enumerate items}[default]



%% Beamer Behaviour
\AtBeginPart{}
\AtBeginSection{}
\AtBeginSubsection{}
\AtBeginSubsubsection{}
\setlength{\emergencystretch}{0em}
\setlength{\parskip}{0pt}



%% Front matter conditionals.
\title[Stats for ML]{Basic Statistics for Machine Learning}
\subtitle{You Could Call It ``Statistical Learning''}
\author[
D.Pananos
]{Demetri Pananos}
\institute[
]{
		\includegraphics[width=15mm,keepaspectratio]{../western.png}\\
	\vspace{2 mm}
			Department of Epidemiology \& Biostatistics \newline Schulich School of
Medicine \& Dentistry \\
		Western University
	}


\logo{
						\includegraphics[width=7.5mm,keepaspectratio]{../western.png}
		}


\date[
2018-10-24
]{
		2018-10-24
			}


\begin{document}

\begin{frame}[plain]
\titlepage
\end{frame}

\hypertarget{intro}{%
\subsection{Intro}\label{intro}}

\begin{frame}{A First Approximation For The Difference Between ML and
SL}
\protect\hypertarget{a-first-approximation-for-the-difference-between-ml-and-sl}{}

\begin{itemize}
\item
  Some algorithms are built off of statistical concepts.
\item
  Others seem ad hoc, with no immediate relationship to a statistical
  theory
\item
  I would call the former \emph{statistical learning algorithms} and the
  latter \emph{machine learning algorithms}.
\end{itemize}

\end{frame}

\begin{frame}{A First Approximation For The Difference Between ML and
SL}
\protect\hypertarget{a-first-approximation-for-the-difference-between-ml-and-sl-1}{}

The name ``machine learning'' is an unfortunate name. The machine
``learns'' the neccesary associations in both types of learning.

\end{frame}

\begin{frame}{A First Approximation For The Difference Between ML and
SL}
\protect\hypertarget{a-first-approximation-for-the-difference-between-ml-and-sl-2}{}

E.g. * Generalized Linear Models are Statistical Learning * Neural Nets
are Machine Learning

\end{frame}

\begin{frame}{Goals}
\protect\hypertarget{goals}{}

\begin{itemize}
\tightlist
\item
  Be able to understand what the chosen algorithm does
\item
  Be able to explain it in laymen's/sophmoric terminology
\end{itemize}

\end{frame}

\begin{frame}{Will Require an Understanding of The Following}
\protect\hypertarget{will-require-an-understanding-of-the-following}{}

\begin{itemize}
\item
  Manipulation of Probabilities
\item
  Expectations and Covariance
\item
  The Very Basics of Likelihood Theory
\end{itemize}

\end{frame}

\hypertarget{probability}{%
\subsection{Probability}\label{probability}}

\begin{frame}{Probability}
\protect\hypertarget{probability-1}{}

Sum Rule

\[P(X) = \sum_Y P(X,Y)\]

Product/Chain Rule

\[P(X,Y) = P(Y|X)P(X)\]

\end{frame}

\begin{frame}{Probability}
\protect\hypertarget{probability-2}{}

We can recover some very powerful rules just from these. \newline Bayes'
Rule

\[P(Y|X) = \dfrac{P(X|Y)P(Y)}{\displaystyle{\sum_Y} P(X|Y)P(Y) }\]

\end{frame}



\end{document}